import re
from modules.core.openai_client import client as openai_client
from modules.core.logger import logger

# üîß Keywords ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ
COMMON_GREETINGS = [
    "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ", "‡∏´‡∏ß‡∏±‡∏î‡∏î‡∏µ", "‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö", "‡∏î‡∏µ‡∏à‡πâ‡∏≤", "‡πÄ‡∏Æ‡∏•‡πÇ‡∏´‡∏•", "hello", "hi", "‡∏ó‡∏±‡∏Å", "‡∏Æ‡∏±‡∏•‡πÇ‡∏´‡∏•", "‡πÇ‡∏¢‡πà"
]

def is_greeting(text: str) -> bool:
    return any(greet in text.lower() for greet in COMMON_GREETINGS)

def is_question(text: str) -> bool:
    QUESTION_HINTS = ["‡∏Ñ‡∏∑‡∏≠", "‡∏≠‡∏∞‡πÑ‡∏£", "‡πÉ‡∏Ñ‡∏£", "‡∏¢‡∏±‡∏á‡πÑ‡∏á", "‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏≠‡∏∞‡πÑ‡∏£", "‡∏ó‡∏≥‡πÑ‡∏°", "‡∏´‡∏£‡∏≠", "?"]
    return any(hint in text for hint in QUESTION_HINTS) or text.strip().endswith("?")

def is_about_bot(text: str) -> bool:
    patterns = [
        r"\b(‡∏û‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏°|‡∏û‡∏£‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏°|bot|‡∏ö‡∏≠‡∏ó|gpt|‡∏Ñ‡∏∏‡∏ì‡∏´‡∏•‡∏≤‡∏°)\b",
        r"‡∏ä‡∏∑‡πà‡∏≠.*(‡∏ö‡∏≠‡∏ó|‡∏û‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏°)",
        r"(‡∏û‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏°|‡∏ö‡∏≠‡∏ó).*(‡∏ó‡∏≥‡∏á‡∏≤‡∏ô|‡∏ï‡∏≠‡∏ö|‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ|‡πÄ‡∏Å‡∏¥‡∏î|‡∏™‡∏£‡πâ‡∏≤‡∏á|‡∏°‡∏µ‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï|‡∏û‡∏π‡∏î|‡∏£‡∏π‡πâ|‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å|‡∏Ñ‡∏∑‡∏≠)",
        r"(‡πÉ‡∏Ñ‡∏£.*(‡∏™‡∏£‡πâ‡∏≤‡∏á|‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô|‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠))",
    ]
    text = text.lower()
    return any(re.search(p, text) for p in patterns)

async def get_openai_response(
    messages: list,
    model: str = "gpt-4o-mini",
    max_tokens: int = 1800,
    temperature: float = 0.6,
    top_p: float = 1.0,
    frequency_penalty: float = 0.2,
    presence_penalty: float = 0.3,
) -> str:
    try:
        response = await openai_client.chat.completions.create(
            model=model,
            messages=messages,
            max_tokens=max_tokens,
            temperature=temperature,
            top_p=top_p,
            frequency_penalty=frequency_penalty,
            presence_penalty=presence_penalty,
        )

        # ‚úÖ log token usage (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ usage object)
        if hasattr(response, "usage") and response.usage:
            input_tokens = response.usage.prompt_tokens
            output_tokens = response.usage.completion_tokens
            total_tokens = response.usage.total_tokens
            logger.info(f"üßÆ Token Usage ‚Üí Input: {input_tokens} | Output: {output_tokens} | Total: {total_tokens}")

        # ‚úÖ ‡∏î‡∏∂‡∏á content ‡∏≠‡∏≠‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
        if response.choices and response.choices[0].message and response.choices[0].message.content:
            content = response.choices[0].message.content.strip()
            return content
        else:
            logger.warning("‚ö†Ô∏è No valid choices returned from OpenAI")
            return "‚ö†Ô∏è ‡∏û‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏°‡∏á‡∏á‡πÄ‡∏•‡∏¢ ‡∏ï‡∏≠‡∏ö‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á ‡πÜ ‡∏à‡πâ‡∏≤"

    except Exception as e:
        logger.error(f"‚ùå GPT Error: {e}")
        return "‚ö†Ô∏è ‡∏û‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏°‡∏Ç‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏á‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß ‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö"
